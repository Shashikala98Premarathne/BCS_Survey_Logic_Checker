{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# BCS Survey Logic Checker (with row-level details)\n",
    "# ==========================================================\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import json\n",
    "import csv\n",
    "from io import BytesIO\n",
    "import io\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# App setup + theme\n",
    "# -------------------------------------------------------------------\n",
    "st.set_page_config(page_title=\"BCS Survey Logic Checker\", layout=\"wide\")\n",
    "\n",
    "def set_background_solid(main=\"#F4EB89\", sidebar=\"#EEEFF3\"):\n",
    "    st.markdown(f\"\"\"\n",
    "    <style>\n",
    "      [data-testid=\"stAppViewContainer\"],\n",
    "      [data-testid=\"stAppViewContainer\"] .main,\n",
    "      [data-testid=\"stAppViewContainer\"] .block-container {{\n",
    "        background-color: {main} !important;\n",
    "      }}\n",
    "      [data-testid=\"stSidebar\"],\n",
    "      [data-testid=\"stSidebar\"] > div,\n",
    "      [data-testid=\"stSidebar\"] .block-container {{\n",
    "        background-color: {sidebar} !important;\n",
    "      }}\n",
    "      header[data-testid=\"stHeader\"] {{ background: transparent; }}\n",
    "      [data-testid=\"stDataFrame\"],\n",
    "      [data-testid=\"stTable\"] {{ background-color: transparent !important; }}\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "set_background_solid()\n",
    "st.title(\"ðŸ“Š BCS Survey Logic Checker\")\n",
    "st.caption(\"This tool is specifically designed for BCS Thailand/Taiwan. Identified mismatches will be highlighted in the deliverables.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# File helpers\n",
    "# -------------------------------------------------------------------\n",
    "COMMON_ENCODINGS = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\n",
    "ZIP_SIGNATURES = (b\"PK\\x03\\x04\", b\"PK\\x05\\x06\", b\"PK\\x07\\x08\")\n",
    "\n",
    "def _sniff_sep(sample_text: str) -> str:\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample_text[:4096], delimiters=\",;\\t|\")\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        return \",\"\n",
    "\n",
    "def _norm_delim(sel: str) -> str:\n",
    "    return {\"\\\\t\": \"\\t\"}.get(sel, sel)\n",
    "\n",
    "def read_any_table(uploaded_file, enc_override=\"auto\", delim_override=\"auto\", skip_bad=True) -> pd.DataFrame:\n",
    "    name = (uploaded_file.name or \"\").lower()\n",
    "    raw = uploaded_file.read()\n",
    "\n",
    "    if raw.startswith(ZIP_SIGNATURES) or name.endswith((\".xlsx\", \".xls\")):\n",
    "        uploaded_file.seek(0)\n",
    "        return pd.read_excel(uploaded_file)\n",
    "\n",
    "    encodings = COMMON_ENCODINGS if enc_override == \"auto\" else [enc_override]\n",
    "    for enc_try in encodings:\n",
    "        try:\n",
    "            text = raw.decode(enc_try, errors=\"strict\")\n",
    "            sep = _sniff_sep(text) if delim_override == \"auto\" else _norm_delim(delim_override)\n",
    "            kwargs = dict(encoding=enc_try, sep=sep, engine=\"python\")\n",
    "            if skip_bad:\n",
    "                kwargs[\"on_bad_lines\"] = \"skip\"\n",
    "            return pd.read_csv(BytesIO(raw), **kwargs)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    sep = \",\" if delim_override == \"auto\" else _norm_delim(delim_override)\n",
    "    kwargs = dict(encoding=\"latin-1\", sep=sep, engine=\"python\")\n",
    "    if skip_bad:\n",
    "        kwargs[\"on_bad_lines\"] = \"skip\"\n",
    "    return pd.read_csv(BytesIO(raw), **kwargs)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Sidebar upload\n",
    "# -------------------------------------------------------------------\n",
    "with st.sidebar:\n",
    "    st.header(\"Input\")\n",
    "    data_file = st.file_uploader(\"Current wave data\", type=[\"csv\", \"xlsx\", \"xls\"])\n",
    "    rules_file = st.file_uploader(\"Optional: custom rules JSON\", type=[\"json\"])\n",
    "    rules = json.load(rules_file) if rules_file else None\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Parser overrides\")\n",
    "    enc = st.selectbox(\"Encoding\", [\"auto\", \"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"], index=0)\n",
    "    delim = st.selectbox(\"Delimiter\", [\"auto\", \",\", \";\", \"\\\\t\", \"|\"], index=0)\n",
    "    skip_bad = st.checkbox(\"Skip bad lines\", value=True)\n",
    "\n",
    "if not data_file:\n",
    "    st.info(\"Upload a CSV/XLSX to begin.\")\n",
    "    st.stop()\n",
    "\n",
    "try:\n",
    "    data_file.seek(0)\n",
    "    df = read_any_table(data_file, enc_override=enc, delim_override=delim, skip_bad=skip_bad)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to read file: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Clean null tokens\n",
    "# -------------------------------------------------------------------\n",
    "df.replace(\n",
    "    {\"#NULL!\": np.nan, \"NULL\": np.nan, \"null\": np.nan, \"NaN\": np.nan, \"nan\": np.nan,\n",
    "     \"\": np.nan, \"na\": np.nan, \"N/A\": np.nan, \"n/a\": np.nan},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rules list (global only)\n",
    "# -------------------------------------------------------------------\n",
    "SURVEY_RULES = {\n",
    "    1: \"Main brand must exist\",\n",
    "    2: \"Quota make autocoded\",\n",
    "    3: \"Company position requires OE if 98\",\n",
    "    4: \"Fleet size numeric (0â€“99999), terminate if 0\",\n",
    "    5: \"Last purchase required if S3>0\",\n",
    "    6: \"Usage single brand â†’ main_brand must match\",\n",
    "    10: \"Quota make satisfaction set required\",\n",
    "    11: \"Truck defects â†’ require OE\",\n",
    "    12: \"Volvo quota â†’ require satisfaction & dissatisfaction comments\",\n",
    "    13: \"Barriers â†’ require follow-ups\",\n",
    "    14: \"Transport type=98 â†’ require OE\",\n",
    "    15: \"Quota make in Volvo group â†’ require operation range\",\n",
    "    16: \"System fields (region, country, survey_year) required\",\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Check engine (row-level)\n",
    "# -------------------------------------------------------------------\n",
    "digest = []\n",
    "detailed = []\n",
    "\n",
    "def add_issue(rule_id, msg, idx=None):\n",
    "    digest.append((rule_id, msg))\n",
    "    if idx is not None:\n",
    "        detailed.append((idx, rule_id, msg))\n",
    "\n",
    "# Rule 1 â€“ main_brand\n",
    "if \"main_brand\" not in df.columns:\n",
    "    add_issue(1, \"Missing main_brand column\")\n",
    "else:\n",
    "    if df[\"main_brand\"].isna().any():\n",
    "        bad = df[df[\"main_brand\"].isna()].index\n",
    "        for i in bad: add_issue(1, \"main_brand missing\", i)\n",
    "\n",
    "# Rule 2 â€“ quota_make\n",
    "if \"quota_make\" not in df.columns:\n",
    "    add_issue(2, \"Missing quota_make column\")\n",
    "elif \"main_brand\" in df.columns:\n",
    "    bad = df[\"quota_make\"].astype(str) != df[\"main_brand\"].astype(str)\n",
    "    for i in df[bad].index: add_issue(2, \"quota_make â‰  main_brand\", i)\n",
    "\n",
    "# Rule 3 â€“ company_position\n",
    "if \"company_position\" not in df.columns:\n",
    "    add_issue(3, \"Missing company_position\")\n",
    "else:\n",
    "    if (df[\"company_position\"] == 98).any():\n",
    "        if \"company_position_other_specify\" not in df.columns:\n",
    "            for i in df[df[\"company_position\"]==98].index:\n",
    "                add_issue(3, \"Missing OE for company_position=98\", i)\n",
    "\n",
    "# Rule 4 â€“ fleet size\n",
    "if \"n_heavy_duty_trucks\" not in df.columns:\n",
    "    add_issue(4, \"Missing n_heavy_duty_trucks\")\n",
    "else:\n",
    "    vals = pd.to_numeric(df[\"n_heavy_duty_trucks\"], errors=\"coerce\")\n",
    "    for i in df[vals.isna()].index: add_issue(4, \"Invalid numeric S3\", i)\n",
    "    for i in df[(vals < 0) | (vals > 99999)].index: add_issue(4, \"S3 out of range\", i)\n",
    "    for i in df[vals==0].index: add_issue(4, \"S3=0 (terminate)\", i)\n",
    "\n",
    "# Rule 5 â€“ last_purchase_hdt\n",
    "if \"last_purchase_hdt\" not in df.columns:\n",
    "    add_issue(5, \"Missing last_purchase_hdt\")\n",
    "\n",
    "# Rule 6 â€“ usage vs main_brand\n",
    "usage_cols = [c for c in df.columns if c.startswith(\"usage_\")]\n",
    "if usage_cols and \"main_brand\" in df.columns and \"A2b\" in df.columns:\n",
    "    one_brand = df[usage_cols].sum(axis=1) == 1\n",
    "    bad = one_brand & (df[\"A2b\"].astype(str) != df[\"main_brand\"].astype(str))\n",
    "    for i in df[bad].index: add_issue(6, \"A2b â‰  single usage brand\", i)\n",
    "\n",
    "# Rule 10 â€“ quota satisfaction set\n",
    "quota_checks = [\"overall_satisfaction\",\"likelihood_choose_brand\",\"likelihood_choose_workshop\",\"preference_strength\",\"overall_rating_truck\"]\n",
    "for c in quota_checks:\n",
    "    if c not in df.columns:\n",
    "        add_issue(10, f\"Missing {c}\")\n",
    "\n",
    "# Rule 11 â€“ truck defects\n",
    "if \"truck_defects\" in df.columns and (df[\"truck_defects\"]==1).any():\n",
    "    if \"truck_defects_other_specify\" not in df.columns:\n",
    "        for i in df[df[\"truck_defects\"]==1].index:\n",
    "            add_issue(11, \"Missing OE for truck_defects=1\", i)\n",
    "\n",
    "# Rule 12 â€“ Volvo quota\n",
    "if \"quota_make\" in df.columns and (df[\"quota_make\"].astype(str)==\"38\").any():\n",
    "    for c in [\"satisfaction_comments\",\"dissatisfaction_comments\"]:\n",
    "        if c not in df.columns:\n",
    "            for i in df[df[\"quota_make\"].astype(str)==\"38\"].index:\n",
    "                add_issue(12, f\"Missing {c} for Volvo\", i)\n",
    "\n",
    "# Rule 13 â€“ Barriers\n",
    "if \"reasons_not_consider_volvo\" in df.columns:\n",
    "    for follow, col in [(\"a\",\"a_barriers_follow_up\"),(\"b\",\"b_barriers_follow_up\"),(\"c\",\"c_barriers_follow_up\")]:\n",
    "        if col not in df.columns:\n",
    "            for i in df.index: add_issue(13, f\"Missing {col}\", i)\n",
    "\n",
    "# Rule 14 â€“ transport_type OE\n",
    "if \"transport_type\" in df.columns and (df[\"transport_type\"]==98).any():\n",
    "    if \"transport_type_other_specify\" not in df.columns:\n",
    "        for i in df[df[\"transport_type\"]==98].index:\n",
    "            add_issue(14, \"Missing OE for transport_type=98\", i)\n",
    "\n",
    "# Rule 15 â€“ Volvo group operation range\n",
    "if \"quota_make\" in df.columns and df[\"quota_make\"].astype(str).isin([\"38\",\"31\",\"23\",\"9\"]).any():\n",
    "    if \"operation_range_volvo_hdt\" not in df.columns:\n",
    "        for i in df[df[\"quota_make\"].astype(str).isin([\"38\",\"31\",\"23\",\"9\"])].index:\n",
    "            add_issue(15, \"Missing operation_range_volvo_hdt\", i)\n",
    "\n",
    "# Rule 16 â€“ system fields\n",
    "for sysc in [\"region\",\"country\",\"survey_year\"]:\n",
    "    if sysc not in df.columns:\n",
    "        add_issue(16, f\"Missing {sysc}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Prepare outputs\n",
    "# -------------------------------------------------------------------\n",
    "digest_df = pd.DataFrame(digest, columns=[\"RuleID\",\"Issue\"]).drop_duplicates()\n",
    "detailed_df = pd.DataFrame(detailed, columns=[\"RowID\",\"RuleID\",\"Issue\"])\n",
    "\n",
    "st.subheader(\"Survey Logic Issues\")\n",
    "if digest_df.empty:\n",
    "    st.success(\"âœ… No issues found â€“ dataset follows survey logic.\")\n",
    "else:\n",
    "    st.dataframe(digest_df, use_container_width=True)\n",
    "\n",
    "    # Export to Excel\n",
    "    out = io.BytesIO()\n",
    "    with pd.ExcelWriter(out, engine=\"xlsxwriter\") as writer:\n",
    "        digest_df.to_excel(writer, index=False, sheet_name=\"Digest\")\n",
    "        detailed_df.to_excel(writer, index=False, sheet_name=\"Detailed\")\n",
    "    st.download_button(\n",
    "        \"ðŸ“¥ Download Issues (Excel)\",\n",
    "        data=out.getvalue(),\n",
    "        file_name=\"survey_logic_issues.xlsx\",\n",
    "        mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_VALUES = {\n",
    "    # Grids\n",
    "    \"unaided_aware_b\": [0, 1],\n",
    "    \"usage_b\": [0, 1],\n",
    "    \"consideration_b\": [0, 1],\n",
    "    \"familiarity_b\": [1, 2, 3, 4, 5],\n",
    "    \"overall_impression_b\": list(range(1, 11)),\n",
    "    \"closeness_b\": [1, 2, 3, 4, 5],\n",
    "    \"performance_b\": list(range(1, 11)),\n",
    "    \"image_b\": [1, 2, 3, 4, 5],\n",
    "\n",
    "    # Ratings\n",
    "    \"truck_rating_\": list(range(1, 11)),\n",
    "    \"salesdelivery_rating_\": list(range(1, 11)),\n",
    "    \"workshop_rating_\": list(range(1, 11)),\n",
    "\n",
    "    # Single-choice questions\n",
    "    \"decision_maker\": [1, 2],\n",
    "    \"fleet_knowledge\": [1, 2],\n",
    "    \"company_position\": list(range(1, 99)),\n",
    "    \"transport_type\": list(range(1, 100)),\n",
    "    \"anonymity\": [1, 2],\n",
    "    \"region\": list(range(1, 100)),\n",
    "\n",
    "    # Brand-specific fields\n",
    "    \"main_brand\": [7, 15, 19, 21, 25, 26, 27, 28, 32, 38, 47, 58],\n",
    "    \"quota_make\": [7, 15, 19, 21, 25, 26, 27, 28, 32, 38, 47, 58],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Rule 28 â€“ Value Validation\n",
    "\n",
    "SURVEY_RULES[28] = \"Value Validation â€“ ensure coded variables only use allowed response values\"\n",
    "\n",
    "ALLOWED_VALUES = {\n",
    "    # Awareness / Usage / Consideration grids\n",
    "    \"unaided_aware_b\": [0, 1],\n",
    "    \"usage_b\": [0, 1],\n",
    "    \"consideration_b\": [0, 1],\n",
    "    \"reasons_not_consider_volvo_\": [0, 1],\n",
    "    \"reasons_not_consider_mack_\": [0, 1],\n",
    "    \"reasons_not_consider_renault_\": [0, 1],\n",
    "    \"touchpoints_\" = [0, 1],\n",
    "\n",
    "\n",
    "    # Familiarity / Impression / Closeness / Performance\n",
    "    \"familiarity_b\": [1, 2, 3, 4, 5],\n",
    "    \"overall_impression_b\": list(range(1, 11)),\n",
    "    \"closeness_b\": [1, 2, 3, 4, 5],\n",
    "    \"performance_b\": list(range(1, 11)),\n",
    "\n",
    "    # Image & ratings\n",
    "    \"image_x_b\": [0,1],\n",
    "    \"truck_rating_x_b\":[1,2,3,4,5,9],\n",
    "    \"salesdelivery_rating_\": [1,2,3,4,5,9],\n",
    "    \"workshop_rating_\": [1,2,3,4,5,9],\n",
    "\n",
    "    # General singleâ€“choice variables (adjust when you share full codebook)\n",
    "    \"decision_maker\": [1, 2],\n",
    "    \"fleet_knowledge\": [1, 2],\n",
    "    \"truck_defects\": [1, 2],\n",
    "    \"interview_method\": [1, 2,3],\n",
    "    \"sample_source\": [1, 2],\n",
    "    \"anonymity\": [1, 2],\n",
    "    \"company_position\": [1, 2,3,4,5,6,7,98],\n",
    "    \"operation_range_volvo_hdt\": [1,2,3],\n",
    "    \"transport_type\":[1,2,3,4,5,6,7,8,9,10,11,12,13,98],\n",
    "}\n",
    "\n",
    "for prefix, allowed_values in ALLOWED_VALUES.items():\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    for c in cols:\n",
    "        series = df[c].dropna().astype(str).str.strip()\n",
    "        invalid_mask = ~series.isin([str(v) for v in allowed_values])\n",
    "        if invalid_mask.any():\n",
    "            for i in df[invalid_mask.index[invalid_mask]].index:\n",
    "                bad_val = df.at[i, c]\n",
    "                add_issue(28, f\"{c} has invalid value '{bad_val}' (allowed: {allowed_values})\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Data Range Validation (Global Variable Structure)\n",
    "# -------------------------------------------------------------------\n",
    "VARIABLE_STRUCTURE = {\n",
    "    \"familiarity_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": [1, 2, 3, 4, 5],\n",
    "    },\n",
    "    \"unaided_aware_b\": {\n",
    "        \"suffix_range\": list(range(1, 66)) + [98],\n",
    "        \"allowed_values\": [0, 1],\n",
    "    },\n",
    "    \"usage_b\": {\n",
    "        \"suffix_range\": list(range(1, 66)) + [98],\n",
    "        \"allowed_values\": [0, 1],\n",
    "    },\n",
    "    \"performance_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": list(range(1, 11)),\n",
    "    },\n",
    "    \"closeness_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": list(range(1, 11)),\n",
    "    },\n",
    "    \"consideration_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": [0, 1],\n",
    "    },\n",
    "    \"last_purchase_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": [0, 1,99],\n",
    "    },\n",
    "    \"last_workshop_visit_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": [0, 1,99],\n",
    "    },\n",
    "    \"overall_impression_b\": {\n",
    "        \"suffix_range\": [15, 19, 21, 27, 28, 32, 38, 47, 58, 98],\n",
    "        \"allowed_values\": [1,2,3,4,5],\n",
    "    },\n",
    "    \"image_\": {\n",
    "        \"attribute_range\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,32],\n",
    "        \"brand_range\": list(range(1, 66)) + [98],\n",
    "        \"allowed_values\": [0, 1],\n",
    "    },\n",
    "    \"truck_rating_\": {\n",
    "        \"suffix_range\": list(range(1, 15)),\n",
    "        \"allowed_values\": [1,2,3,4,5,9],   \n",
    "    },\n",
    "    \"salesdelivery_rating_\": {\n",
    "        \"suffix_range\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,17],\n",
    "        \"allowed_values\": [1,2,3,4,5,9],  \n",
    "    },\n",
    "    \"workshop_rating_\": {\n",
    "        \"suffix_range\": list(range(1, 14)),\n",
    "        \"allowed_values\": [1,2,3,4,5,9],   \n",
    "    },      \n",
    "    \"reasons_not_consider_volvo_\": {\n",
    "        \"suffix_range\": list(range(1, 13)) + [98],\n",
    "        \"allowed_values\": [0,1], \n",
    "    },   \n",
    "    \"reasons_not_consider_mack_\": {\n",
    "        \"suffix_range\": list(range(1, 13)) + [98],\n",
    "        \"allowed_values\": [0,1], \n",
    "    },   \n",
    "    \"reasons_not_consider_mack_\": {\n",
    "        \"suffix_range\": list(range(1, 13)) + [98],\n",
    "        \"allowed_values\": [0,1],         \n",
    "    },\n",
    "    \"decision_maker\": [1, 2],\n",
    "    \"fleet_knowledge\": [1, 2],\n",
    "    \"truck_defects\": [1, 2],\n",
    "    \"interview_method\": [1, 2,3],\n",
    "    \"last_purchase_hdt\": [1,2,3,4,5,6,7,8,9],\n",
    "    \"sample_source\": [1, 2],\n",
    "    \"segment\": [1, 2],\n",
    "    \"anonymity\": [1, 2],\n",
    "    \"company_position\": [1, 2,3,4,5,6,7,98],\n",
    "    \"operation_range_volvo_hdt\": [1,2,3],\n",
    "    \"transport_type\":[1,2,3,4,5,6,7,8,9,10,11,12,13,98],\n",
    "    \"main_brand\": [7, 15, 19, 21, 25, 26, 27, 28, 32, 38, 47, 58],\n",
    "    \"quota_make\": [7, 15, 19, 21, 25, 26, 27, 28, 32, 38, 47, 58],\n",
    "    \"preference\": [7, 15, 19, 21, 25, 26, 27, 28, 32, 38, 47, 58,99],\n",
    "}    \n",
    "\n",
    "# Rule 0 â€“ Data Range Validation\n",
    "for prefix, rule in VARIABLE_STRUCTURE.items():\n",
    "\n",
    "    # ---- Normal one-level prefixes ----\n",
    "    if \"suffix_range\" in rule:\n",
    "        suffixes = rule[\"suffix_range\"]\n",
    "        allowed = set(rule[\"allowed_values\"])\n",
    "\n",
    "        for suffix in suffixes:\n",
    "            col = f\"{prefix}{suffix}\"\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            invalid_mask = ~df[col].isin(allowed) & df[col].notna()\n",
    "            invalid_rows = df[invalid_mask].index\n",
    "\n",
    "            for i in invalid_rows:\n",
    "                add_issue(\n",
    "                    0,\n",
    "                    f\"{col} contains invalid value {df.loc[i, col]!r} (allowed: {sorted(allowed)})\",\n",
    "                    i,\n",
    "                )\n",
    "\n",
    "    # ---- Two-level prefixes (like image_<attr>_b<brand>) ----\n",
    "    elif \"attribute_range\" in rule and \"brand_range\" in rule:\n",
    "        attrs = rule[\"attribute_range\"]\n",
    "        brands = rule[\"brand_range\"]\n",
    "        allowed = set(rule[\"allowed_values\"])\n",
    "\n",
    "        for a in attrs:\n",
    "            for b in brands:\n",
    "                col = f\"{prefix}{a}_b{b}\"\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                invalid_mask = ~df[col].isin(allowed) & df[col].notna()\n",
    "                invalid_rows = df[invalid_mask].index\n",
    "\n",
    "                for i in invalid_rows:\n",
    "                    add_issue(\n",
    "                        0,\n",
    "                        f\"{col} contains invalid value {df.loc[i, col]!r} (allowed: {sorted(allowed)})\",\n",
    "                        i,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6dab1",
   "metadata": {},
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e06208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Data Range Validation (Global Variable Structure)\n",
    "# -------------------------------------------------------------------\n",
    "VARIABLE_STRUCTURE = {\n",
    "    \"familiarity_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": [1,2,3,4,5],\n",
    "    },\n",
    "    \"unaided_aware_b\": {\n",
    "        \"suffix_range\": list(range(1,66)) + [98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    \"usage_b\": {\n",
    "        \"suffix_range\": list(range(1,66)) + [98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    \"performance_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": list(range(1,11)),\n",
    "    },\n",
    "    \"closeness_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": list(range(1,11)),\n",
    "    },\n",
    "    \"consideration_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    \"last_purchase_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": [0,1,99],\n",
    "    },\n",
    "    \"last_workshop_visit_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": [0,1,99],\n",
    "    },\n",
    "    \"overall_impression_b\": {\n",
    "        \"suffix_range\": [15,19,21,27,28,32,38,47,58,98],\n",
    "        \"allowed_values\": [1,2,3,4,5],\n",
    "    },\n",
    "    \"image_\": {\n",
    "        \"attribute_range\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,32],\n",
    "        \"brand_range\": list(range(1,66)) + [98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    \"truck_rating_\": {\n",
    "        \"suffix_range\": list(range(1,15)),\n",
    "        \"allowed_values\": [1,2,3,4,5,9],\n",
    "    },\n",
    "    \"salesdelivery_rating_\": {\n",
    "        \"suffix_range\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,17],\n",
    "        \"allowed_values\": [1,2,3,4,5,9],\n",
    "    },\n",
    "    \"workshop_rating_\": {\n",
    "        \"suffix_range\": list(range(1,14)),\n",
    "        \"allowed_values\": [1,2,3,4,5,9],\n",
    "    },\n",
    "    \"reasons_not_consider_volvo_\": {\n",
    "        \"suffix_range\": list(range(1,13)) + [98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    \"reasons_not_consider_mack_\": {\n",
    "        \"suffix_range\": list(range(1,13)) + [98],\n",
    "        \"allowed_values\": [0,1],\n",
    "    },\n",
    "    # Single variables\n",
    "    \"decision_maker\": [1,2],\n",
    "    \"fleet_knowledge\": [1,2],\n",
    "    \"truck_defects\": [1,2],\n",
    "    \"interview_method\": [1,2,3],\n",
    "    \"last_purchase_hdt\": [1,2,3,4,5,6,7,8,9],\n",
    "    \"sample_source\": [1,2],\n",
    "    \"segment\": [1,2],\n",
    "    \"anonymity\": [1,2],\n",
    "    \"company_position\": [1,2,3,4,5,6,7,98],\n",
    "    \"operation_range_volvo_hdt\": [1,2,3],\n",
    "    \"transport_type\": [1,2,3,4,5,6,7,8,9,10,11,12,13,98],\n",
    "    \"main_brand\": [7,15,19,21,25,26,27,28,32,38,47,58],\n",
    "    \"quota_make\": [7,15,19,21,25,26,27,28,32,38,47,58],\n",
    "    \"preference\": [7,15,19,21,25,26,27,28,32,38,47,58,99],\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rule 0 â€“ Data Range Validation\n",
    "# -------------------------------------------------------------------\n",
    "for prefix, rule in VARIABLE_STRUCTURE.items():\n",
    "\n",
    "    # ---- Normal one-level prefixes ----\n",
    "    if isinstance(rule, dict) and \"suffix_range\" in rule:\n",
    "        suffixes = rule[\"suffix_range\"]\n",
    "        allowed = set(rule[\"allowed_values\"])\n",
    "        for suffix in suffixes:\n",
    "            col = f\"{prefix}{suffix}\"\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            invalid_mask = ~df[col].isin(allowed) & df[col].notna()\n",
    "            for i in df[invalid_mask].index:\n",
    "                add_issue(0, f\"{col} contains invalid value {df.loc[i,col]!r} (allowed: {sorted(allowed)})\", i)\n",
    "\n",
    "    # ---- Two-level prefixes (image_<attr>_b<brand>) ----\n",
    "    elif isinstance(rule, dict) and \"attribute_range\" in rule:\n",
    "        attrs = rule[\"attribute_range\"]\n",
    "        brands = rule[\"brand_range\"]\n",
    "        allowed = set(rule[\"allowed_values\"])\n",
    "        for a in attrs:\n",
    "            for b in brands:\n",
    "                col = f\"{prefix}{a}_b{b}\"\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "                invalid_mask = ~df[col].isin(allowed) & df[col].notna()\n",
    "                for i in df[invalid_mask].index:\n",
    "                    add_issue(0, f\"{col} contains invalid value {df.loc[i,col]!r} (allowed: {sorted(allowed)})\", i)\n",
    "\n",
    "    # ---- Single-variable columns ----\n",
    "    elif isinstance(rule, list):\n",
    "        allowed = set(rule)\n",
    "        col = prefix\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        invalid_mask = ~df[col].isin(allowed) & df[col].notna()\n",
    "        for i in df[invalid_mask].index:\n",
    "            add_issue(0, f\"{col} contains invalid value {df.loc[i,col]!r} (allowed: {sorted(allowed)})\", i)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
